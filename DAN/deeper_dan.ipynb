{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ac2bc55e-25ba-47f2-9bae-26f9c955aacf",
      "metadata": {
        "tags": [],
        "id": "ac2bc55e-25ba-47f2-9bae-26f9c955aacf"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader, ConcatDataset\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import random_split\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import pickle\n",
        "import os\n",
        "from PIL import Image\n",
        "import itertools\n",
        "from mnistm import MNISTMDataset\n",
        "from syn_digits import SyntheticDigits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6e471a2c-c924-41a2-96c7-31089c1f9eaa",
      "metadata": {
        "tags": [],
        "id": "6e471a2c-c924-41a2-96c7-31089c1f9eaa",
        "outputId": "18fb767f-4816-4462-bf9b-9e83428fd55c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'NVIDIA GeForce RTX 3080'"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Set device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "torch.cuda.get_device_name()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "013c4535-251b-4b26-b37b-6901caf43f0d",
      "metadata": {
        "id": "013c4535-251b-4b26-b37b-6901caf43f0d"
      },
      "source": [
        "# Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2a7f655d-b343-4a97-9b4c-55d87b031a41",
      "metadata": {
        "tags": [],
        "id": "2a7f655d-b343-4a97-9b4c-55d87b031a41"
      },
      "outputs": [],
      "source": [
        "# Define transformations\n",
        "transform_mnist = transforms.Compose([\n",
        "    transforms.Resize((32, 32)),  # Resize to the same size as used in SVHN)\n",
        "    transforms.Grayscale(num_output_channels=3),  # Convert to 3-channel RGB\n",
        "    transforms.ToTensor(),  # Convert to Tensor\n",
        "    transforms.Normalize((0.5,), (0.5,))  # Normalize (assuming grayscale, same value for all channels)\n",
        "])\n",
        "\n",
        "transform_mnist_m = transforms.Compose([\n",
        "    transforms.Resize((32, 32)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # Normalize for RGB\n",
        "])\n",
        "\n",
        "transform_svhn = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "\n",
        "transform_syn = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "57016f26-a365-4ea2-af5c-3bf844864590",
      "metadata": {
        "tags": [],
        "id": "57016f26-a365-4ea2-af5c-3bf844864590",
        "outputId": "d2fc5afb-e180-4029-a4dd-2aeed17d655d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using downloaded and verified file: ./data\\train_32x32.mat\n",
            "Using downloaded and verified file: ./data\\test_32x32.mat\n",
            "./syn_dataset\\SyntheticDigits\\processed\\synth_train.pt\n",
            "./syn_dataset\\SyntheticDigits\\processed\\synth_test.pt\n"
          ]
        }
      ],
      "source": [
        "# Load datasets\n",
        "mnist_train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform_mnist) # 60000\n",
        "mnist_test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform_mnist) # 10000\n",
        "\n",
        "mnistm_train_dataset = MNISTMDataset(\"./dataset\", train = True, transform=transform_mnist_m) # 59001\n",
        "mnistm_test_dataset = MNISTMDataset(\"./dataset\", train = False, transform=transform_mnist_m) # 9001\n",
        "\n",
        "svhn_train_dataset = datasets.SVHN(root='./data', split='train', download=True, transform=transform_svhn) # 73257\n",
        "svhn_test_dataset = datasets.SVHN(root='./data', split='test', download=True, transform=transform_svhn) # 26032\n",
        "\n",
        "syn_train_dataset = SyntheticDigits(root='./syn_dataset', train=True, transform=transform_syn, target_transform=None, download=True)\n",
        "syn_test_dataset = SyntheticDigits(root='./syn_dataset', train=False, transform=transform_syn, target_transform=None, download=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ad1a125c-55dc-4b68-9a19-b02a3118052b",
      "metadata": {
        "tags": [],
        "id": "ad1a125c-55dc-4b68-9a19-b02a3118052b"
      },
      "outputs": [],
      "source": [
        "batch_size = 64  # Set the batch size\n",
        "\n",
        "total_size = len(mnist_train_dataset)\n",
        "val_size = int(0.15 * total_size)\n",
        "train_size = total_size - val_size\n",
        "train_dataset, val_dataset = random_split(mnist_train_dataset, [train_size, val_size])\n",
        "\n",
        "mnist_train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "mnist_val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
        "mnist_test_loader = DataLoader(mnist_test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "total_size = len(mnistm_train_dataset)\n",
        "val_size = int(0.15 * total_size)\n",
        "train_size = total_size - val_size\n",
        "train_dataset, val_dataset = random_split(mnistm_train_dataset, [train_size, val_size])\n",
        "\n",
        "mnistm_train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "mnistm_val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
        "mnistm_test_loader = DataLoader(mnistm_test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "total_size = len(svhn_train_dataset)\n",
        "val_size = int(0.15 * total_size)\n",
        "train_size = total_size - val_size\n",
        "train_dataset, val_dataset = random_split(svhn_train_dataset, [train_size, val_size])\n",
        "\n",
        "svhn_train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "svhn_val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
        "svhn_test_loader = DataLoader(svhn_test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "total_size = len(syn_train_dataset)\n",
        "val_size = int(0.15 * total_size)\n",
        "train_size = total_size - val_size\n",
        "train_dataset, val_dataset = random_split(syn_train_dataset, [train_size, val_size])\n",
        "\n",
        "syn_train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "syn_val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
        "syn_test_loader = DataLoader(syn_test_dataset, batch_size=batch_size, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "297a13a8-f1f9-4cb9-8360-5f4e02a421e6",
      "metadata": {
        "id": "297a13a8-f1f9-4cb9-8360-5f4e02a421e6"
      },
      "source": [
        "# Model Architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aff56d3a-4379-44af-b549-bdc982b3a232",
      "metadata": {
        "tags": [],
        "id": "aff56d3a-4379-44af-b549-bdc982b3a232"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Feature extractor (e.g., a simple CNN for image tasks)\n",
        "class FeatureExtractor(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(FeatureExtractor, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 32, 3)  # Assuming input images are RGB (3 channels)\n",
        "        self.bn1 = nn.BatchNorm2d(32)\n",
        "        self.conv2 = nn.Conv2d(32, 32, 3)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.drop = nn.Dropout2d()\n",
        "        self.conv3 = nn.Conv2d(32, 64, 3)\n",
        "        self.bn2 = nn.BatchNorm2d(64)\n",
        "        self.conv4 = nn.Conv2d(64, 64, 3)\n",
        "        # Calculate the size of the flattened features after the conv and pooling layers\n",
        "        # After the pooling layers, a 32x32 image becomes 5x5\n",
        "        self.fc1 = nn.Linear(64 * 5 * 5, 128)\n",
        "        self.fc2 = nn.Linear(128, 64)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.bn1(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = self.drop(x)\n",
        "        x = self.bn2(F.relu(self.conv3(x)))\n",
        "        x = self.pool(F.relu(self.conv4(x)))\n",
        "        x = self.drop(x)\n",
        "        x = x.view(-1, 64 * 5 * 5)  # Flatten the output\n",
        "        feature1 = x\n",
        "        x = F.relu(self.fc1(x))\n",
        "        feature2 = x\n",
        "        x = F.relu(self.fc2(x))\n",
        "        return feature1, feature2, x  # This feature vector is passed to the classifier\n",
        "\n",
        "class Classifier(nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(Classifier, self).__init__()\n",
        "        # The input size should match the size of the feature vector from the feature extractor\n",
        "        #self.fc1 = nn.Linear(84, 120)\n",
        "        #self.fc2 = nn.Linear(120, 84)\n",
        "        # The output size should match the number of classes in the classification task\n",
        "        self.fc3 = nn.Linear(64, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        #x = F.relu(self.fc1(x))\n",
        "        #x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x) # Logits for each class\n",
        "        return F.log_softmax(x, dim=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7d689044-e6e9-448f-9d4b-5473b91544e8",
      "metadata": {
        "tags": [],
        "id": "7d689044-e6e9-448f-9d4b-5473b91544e8"
      },
      "outputs": [],
      "source": [
        "class MMDLoss(nn.Module):\n",
        "    def __init__(self, kernel_type='rbf', kernel_mul=2.0, kernel_num=5):\n",
        "        super(MMDLoss, self).__init__()\n",
        "        self.kernel_num = kernel_num\n",
        "        self.kernel_mul = kernel_mul\n",
        "        self.fix_sigma = None\n",
        "        self.kernel_type = kernel_type\n",
        "\n",
        "    def guassian_kernel(self, source, target, kernel_mul, kernel_num, fix_sigma):\n",
        "        n_samples = int(source.size()[0])+int(target.size()[0])\n",
        "        total = torch.cat([source, target], dim=0)\n",
        "\n",
        "        total0 = total.unsqueeze(0).expand(int(total.size(0)), int(total.size(0)), int(total.size(1)))\n",
        "        total1 = total.unsqueeze(1).expand(int(total.size(0)), int(total.size(0)), int(total.size(1)))\n",
        "        L2_distance = ((total0-total1)**2).sum(2)\n",
        "        L2_distance = torch.clamp(L2_distance, min=1e-8)\n",
        "        #print(L2_distance)\n",
        "        if fix_sigma:\n",
        "            bandwidth = fix_sigma\n",
        "        else:\n",
        "            bandwidth = torch.sum(L2_distance.data) / (n_samples**2-n_samples)\n",
        "\n",
        "        bandwidth /= kernel_mul ** (kernel_num // 2)\n",
        "        bandwidth_list = [bandwidth * (kernel_mul**i) for i in range(kernel_num)]\n",
        "        kernel_val = [torch.exp(-L2_distance / bandwidth_temp) for bandwidth_temp in bandwidth_list]\n",
        "        return sum(kernel_val)\n",
        "\n",
        "    def forward(self, source, target):\n",
        "        if self.kernel_type == 'rbf':\n",
        "            batch_size = int(source.size()[0])\n",
        "            kernels = self.guassian_kernel(source, target, kernel_mul=self.kernel_mul, kernel_num=self.kernel_num, fix_sigma=self.fix_sigma)\n",
        "            XX = torch.mean(kernels[:batch_size, :batch_size])\n",
        "            #print(\"XX: \", XX)\n",
        "            YY = torch.mean(kernels[batch_size:, batch_size:])\n",
        "            #print(\"YY: \", YY)\n",
        "            XY = torch.mean(kernels[:batch_size, batch_size:])\n",
        "            #print(\"XY: \", XY)\n",
        "            YX = torch.mean(kernels[batch_size:, :batch_size])\n",
        "            #print(\"YX: \", YX)\n",
        "            loss = torch.mean(XX + YY - XY - YX)\n",
        "            #print(\"loss: \", loss)\n",
        "            return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fc147bc9-e059-4c08-9b16-ff96f58e654f",
      "metadata": {
        "tags": [],
        "id": "fc147bc9-e059-4c08-9b16-ff96f58e654f"
      },
      "outputs": [],
      "source": [
        "feature_extractor = FeatureExtractor().to(device)\n",
        "classifier = Classifier().to(device)\n",
        "mmd_loss = MMDLoss().to(device)\n",
        "\n",
        "# Standard classification loss\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "optimizer = torch.optim.Adam(list(feature_extractor.parameters()) + list(classifier.parameters()), lr=0.001)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b582033b-8a96-4324-acf0-2e77678b9bae",
      "metadata": {
        "tags": [],
        "id": "b582033b-8a96-4324-acf0-2e77678b9bae"
      },
      "outputs": [],
      "source": [
        "def train(epoch, source_loader, target_loader):\n",
        "    feature_extractor.train()\n",
        "    classifier.train()\n",
        "\n",
        "    total_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for batch_idx, (source_data, target_data) in enumerate(zip(source_loader, target_loader)):\n",
        "        source_inputs, source_labels = source_data\n",
        "        # print(source_inputs.shape)\n",
        "        target_inputs, _ = target_data  # Target labels are not used\n",
        "        #print(target_inputs.shape)\n",
        "        source_inputs, source_labels = source_inputs.to(device), source_labels.to(device)\n",
        "        target_inputs = target_inputs.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        # Forward pass through the feature extractor and classifier\n",
        "        source_f1, source_f2, source_features = feature_extractor(source_inputs)\n",
        "        class_outputs = classifier(source_features)\n",
        "        # print(class_outputs.shape)\n",
        "        tar_f1, tar_f2, target_features = feature_extractor(target_inputs)\n",
        "\n",
        "        # Compute classification loss on source domain\n",
        "        cls_loss = criterion(class_outputs, source_labels)\n",
        "\n",
        "        #if torch.isnan(target_features).any():\n",
        "            #print(\"NaNs in feature extractor output\")\n",
        "\n",
        "        # Compute MMD loss\n",
        "        mmd = mmd_loss(source_f1.double(), tar_f1.double())\n",
        "        mmd += mmd_loss(source_f2.double(), tar_f2.double())\n",
        "        mmd += mmd_loss(source_features.double(), target_features.double())\n",
        "\n",
        "        # Combine losses\n",
        "        loss = cls_loss + 0.1*mmd\n",
        "        #print(\"loss: \", loss)\n",
        "        total_loss += loss\n",
        "\n",
        "        #print(total_loss)\n",
        "        # Backward pass\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Compute accuracy\n",
        "        _, predicted = torch.max(class_outputs.data, 1)\n",
        "        total += source_labels.size(0)\n",
        "        correct += (predicted == source_labels).sum().item()\n",
        "\n",
        "    print('Train Epoch: {} \\tLoss: {:.6f} \\tAccuracy: {:.2f}%'.format(\n",
        "        epoch, total_loss / (batch_idx + 1), 100. * correct / total))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9f5e6736-597d-49cf-994d-35feedc8779e",
      "metadata": {
        "tags": [],
        "id": "9f5e6736-597d-49cf-994d-35feedc8779e"
      },
      "outputs": [],
      "source": [
        "def validate(loader):\n",
        "    feature_extractor.eval()\n",
        "    classifier.eval()\n",
        "\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            _, _, features = feature_extractor(inputs)\n",
        "            outputs = classifier(features)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            test_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    test_loss /= len(loader)\n",
        "    accuracy = 100. * correct / total\n",
        "    print('\\nValidation set: Average loss: {:.4f}, Accuracy: {:.2f}%\\n'.format(test_loss, accuracy))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3514b7dd-f672-4af1-abdf-a35d7e52bcb8",
      "metadata": {
        "tags": [],
        "id": "3514b7dd-f672-4af1-abdf-a35d7e52bcb8",
        "outputId": "e5902ac9-74d7-4397-c217-15ffcb78d5f4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Epoch: 1 \tLoss: 0.579821 \tAccuracy: 82.13%\n",
            "\n",
            "Validation set: Average loss: 0.8252, Accuracy: 74.22%\n",
            "\n",
            "Train Epoch: 2 \tLoss: 0.263379 \tAccuracy: 92.83%\n",
            "\n",
            "Validation set: Average loss: 0.7837, Accuracy: 76.83%\n",
            "\n",
            "Train Epoch: 3 \tLoss: 0.213972 \tAccuracy: 94.29%\n",
            "\n",
            "Validation set: Average loss: 0.7101, Accuracy: 79.09%\n",
            "\n",
            "Train Epoch: 4 \tLoss: 0.193516 \tAccuracy: 94.97%\n",
            "\n",
            "Validation set: Average loss: 0.7692, Accuracy: 78.48%\n",
            "\n",
            "Train Epoch: 5 \tLoss: 0.178023 \tAccuracy: 95.42%\n",
            "\n",
            "Validation set: Average loss: 0.7016, Accuracy: 79.03%\n",
            "\n",
            "Train Epoch: 6 \tLoss: 0.167565 \tAccuracy: 95.72%\n",
            "\n",
            "Validation set: Average loss: 0.7037, Accuracy: 80.00%\n",
            "\n",
            "Train Epoch: 7 \tLoss: 0.153118 \tAccuracy: 96.18%\n",
            "\n",
            "Validation set: Average loss: 0.7150, Accuracy: 79.90%\n",
            "\n",
            "Train Epoch: 8 \tLoss: 0.146427 \tAccuracy: 96.30%\n",
            "\n",
            "Validation set: Average loss: 0.7393, Accuracy: 79.44%\n",
            "\n",
            "Train Epoch: 9 \tLoss: 0.141679 \tAccuracy: 96.66%\n",
            "\n",
            "Validation set: Average loss: 0.6898, Accuracy: 79.91%\n",
            "\n",
            "Train Epoch: 10 \tLoss: 0.138052 \tAccuracy: 96.69%\n",
            "\n",
            "Validation set: Average loss: 0.7032, Accuracy: 80.03%\n",
            "\n",
            "\n",
            "Validation set: Average loss: 0.5280, Accuracy: 85.53%\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(1, 11):\n",
        "    train(epoch, source_loader=syn_train_loader, target_loader=svhn_train_loader)\n",
        "    # scheduler.step()\n",
        "    validate(svhn_val_loader)  # Assuming target_loader is your validation set\n",
        "validate(svhn_test_loader)  # Run the validation function on the test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "811b4f1e-102f-48ed-92b9-6fdd4e6dd40c",
      "metadata": {
        "tags": [],
        "id": "811b4f1e-102f-48ed-92b9-6fdd4e6dd40c",
        "outputId": "06f1bdbd-6eb7-4279-d7bf-e5cd2ca84076"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Validation set: Average loss: 0.6621, Accuracy: 85.80%\n",
            "\n"
          ]
        }
      ],
      "source": [
        "validate(mnist_test_loader)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9eee09b7",
      "metadata": {
        "id": "9eee09b7"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eb351e20",
      "metadata": {
        "id": "eb351e20",
        "outputId": "6cb54567-7f7a-41df-ca91-9d40c37dd995"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Validation set: Average loss: 1.7577, Accuracy: 55.04%\n",
            "\n"
          ]
        }
      ],
      "source": [
        "validate(mnistm_test_loader)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}