{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## baseline model"
      ],
      "metadata": {
        "id": "dDoH0iBs-Inf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import os\n",
        "import torch.backends.cudnn as cudnn\n",
        "import torch.optim as optim\n",
        "import torch.utils.data\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms\n",
        "import numpy as np\n"
      ],
      "metadata": {
        "id": "CeMdk_Ep1aPw"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.utils.data as data\n",
        "from PIL import Image\n",
        "import os\n",
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "class GetLoader(data.Dataset):\n",
        "    def __init__(self, data_root, data_list, transform=None):\n",
        "        self.root = data_root\n",
        "        self.transform = transform\n",
        "\n",
        "        f = open(data_list, 'r')\n",
        "        data_list = f.readlines()\n",
        "        f.close()\n",
        "\n",
        "        self.n_data = len(data_list)\n",
        "\n",
        "        self.img_paths = []\n",
        "        self.img_labels = []\n",
        "\n",
        "        for data in data_list:\n",
        "            self.img_paths.append(data[:-3])\n",
        "            self.img_labels.append(data[-2])\n",
        "\n",
        "    def __getitem__(self, item):\n",
        "        img_paths, labels = self.img_paths[item], self.img_labels[item]\n",
        "        imgs = Image.open(os.path.join(self.root, img_paths)).convert('RGB')\n",
        "\n",
        "        if self.transform is not None:\n",
        "            imgs = self.transform(imgs)\n",
        "            labels = int(labels)\n",
        "\n",
        "        return imgs, labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.n_data"
      ],
      "metadata": {
        "id": "6kj1ibAV-TCH"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import warnings\n",
        "\n",
        "import torch\n",
        "from PIL import Image\n",
        "from torchvision.datasets import VisionDataset\n",
        "from torchvision.datasets.utils import download_and_extract_archive\n",
        "\n",
        "\n",
        "class SyntheticDigits(VisionDataset):\n",
        "    \"\"\"Synthetic Digits Dataset.\n",
        "    \"\"\"\n",
        "\n",
        "    resources = [\n",
        "        ('https://github.com/liyxi/synthetic-digits/releases/download/data/synth_train.pt.gz',\n",
        "         'd0e99daf379597e57448a89fc37ae5cf'),\n",
        "        ('https://github.com/liyxi/synthetic-digits/releases/download/data/synth_test.pt.gz',\n",
        "         '669d94c04d1c91552103e9aded0ee625')\n",
        "    ]\n",
        "\n",
        "    training_file = \"synth_train.pt\"\n",
        "    test_file = \"synth_test.pt\"\n",
        "    classes = ['0 - zero', '1 - one', '2 - two', '3 - three', '4 - four',\n",
        "               '5 - five', '6 - six', '7 - seven', '8 - eight', '9 - nine']\n",
        "\n",
        "    @property\n",
        "    def train_labels(self):\n",
        "        warnings.warn(\"train_labels has been renamed targets\")\n",
        "        return self.targets\n",
        "\n",
        "    @property\n",
        "    def test_labels(self):\n",
        "        warnings.warn(\"test_labels has been renamed targets\")\n",
        "        return self.targets\n",
        "\n",
        "    @property\n",
        "    def train_data(self):\n",
        "        warnings.warn(\"train_data has been renamed data\")\n",
        "        return self.data\n",
        "\n",
        "    @property\n",
        "    def test_data(self):\n",
        "        warnings.warn(\"test_data has been renamed data\")\n",
        "        return self.data\n",
        "\n",
        "    def __init__(self, root, train=True, transform=None, target_transform=None, download=False):\n",
        "        \"\"\"Init Synthetic Digits dataset.\"\"\"\n",
        "        super(SyntheticDigits, self).__init__(root, transform=transform, target_transform=target_transform)\n",
        "\n",
        "        self.train = train\n",
        "\n",
        "        if download:\n",
        "            self.download()\n",
        "\n",
        "        if not self._check_exists():\n",
        "            raise RuntimeError(\"Dataset not found.\" +\n",
        "                               \" You can use download=True to download it\")\n",
        "\n",
        "        if self.train:\n",
        "            data_file = self.training_file\n",
        "        else:\n",
        "            data_file = self.test_file\n",
        "\n",
        "        print(os.path.join(self.processed_folder, data_file))\n",
        "\n",
        "        self.data, self.targets = torch.load(os.path.join(self.processed_folder, data_file))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        \"\"\"Get images and target for data loader.\n",
        "        Args:\n",
        "            index (int): Index\n",
        "        Returns:\n",
        "            tuple: (image, target) where target is index of the target class.\n",
        "        \"\"\"\n",
        "        img, target = self.data[index], int(self.targets[index])\n",
        "\n",
        "        # doing this so that it is consistent with all other datasets\n",
        "        # to return a PIL Image\n",
        "        img = Image.fromarray(img.squeeze().numpy(), mode=\"RGB\")\n",
        "\n",
        "        if self.transform is not None:\n",
        "            img = self.transform(img)\n",
        "\n",
        "        if self.target_transform is not None:\n",
        "            target = self.target_transform(target)\n",
        "\n",
        "        return img, target\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"Return size of dataset.\"\"\"\n",
        "        return len(self.data)\n",
        "\n",
        "    @property\n",
        "    def raw_folder(self):\n",
        "        return os.path.join(self.root, self.__class__.__name__, 'raw')\n",
        "\n",
        "    @property\n",
        "    def processed_folder(self):\n",
        "        return os.path.join(self.root, self.__class__.__name__, 'processed')\n",
        "\n",
        "    @property\n",
        "    def class_to_idx(self):\n",
        "        return {_class: i for i, _class in enumerate(self.classes)}\n",
        "\n",
        "    def _check_exists(self):\n",
        "        return (os.path.exists(os.path.join(self.processed_folder, self.training_file)) and\n",
        "                os.path.exists(os.path.join(self.processed_folder, self.test_file)))\n",
        "\n",
        "    def download(self):\n",
        "        \"\"\"Download the Synthetic Digits data.\"\"\"\n",
        "\n",
        "        if self._check_exists():\n",
        "            return\n",
        "\n",
        "        os.makedirs(self.raw_folder, exist_ok=True)\n",
        "        os.makedirs(self.processed_folder, exist_ok=True)\n",
        "\n",
        "        # download files\n",
        "        for url, md5 in self.resources:\n",
        "            filename = url.rpartition('/')[2]\n",
        "            download_and_extract_archive(url, download_root=self.raw_folder,\n",
        "                                         extract_root=self.processed_folder,\n",
        "                                         filename=filename, md5=md5)\n",
        "\n",
        "        print('Done!')\n",
        "\n",
        "    def extra_repr(self):\n",
        "        return \"Split: {}\".format(\"Train\" if self.train is True else \"Test\")"
      ],
      "metadata": {
        "id": "gSNTdJZgGZsy"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform_syn = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Resize(32),\n",
        "    transforms.Normalize((0.4377, 0.4438, 0.4728), (0.1980, 0.2010, 0.1970))\n",
        "])\n",
        "\n",
        "# Transform for SVHN\n",
        "transform_svhn = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    # transforms.Resize(28),\n",
        "    transforms.Normalize((0.4377, 0.4438, 0.4728), (0.1980, 0.2010, 0.1970))\n",
        "])\n",
        "\n",
        "# Transform for MNIST\n",
        "transform_mnist = transforms.Compose([\n",
        "    transforms.Resize(32),  # Resize MNIST images to 32x32 to match SVHN format\n",
        "    transforms.Grayscale(3),  # Convert MNIST images to 3 channels\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.1307,), (0.3081,))\n",
        "])\n",
        "\n",
        "# Transform for MNIST-M\n",
        "transform_mnistm = transforms.Compose([\n",
        "    transforms.Resize((32, 32)),  # Resize MNIST images to 32x32 to match SVHN format\n",
        "    transforms.Grayscale(3),  # Convert MNIST images to 3 channels\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.1307,), (0.3081,))\n",
        "])\n",
        "batch_size = 128"
      ],
      "metadata": {
        "id": "R1tVJ8fgG5jv"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# # Load target SVHN dataset\n",
        "source_svhn_dataset = datasets.SVHN(root='./data', split='train', download=True, transform=transform_svhn)\n",
        "dataloader_svhn_source = DataLoader(source_svhn_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# Load source Syn Digits dataset\n",
        "# source_syn_dataset = SyntheticDigits(root='./syn_dataset', train=True, download=True, transform=transform_syn)\n",
        "# dataloader_syn_source = DataLoader(source_syn_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# Load source MNIST Digits dataset\n",
        "# source_mnist_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform_mnist)\n",
        "# dataloader_mnist_source = DataLoader(source_mnist_dataset, batch_size=batch_size, shuffle=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tg0dQZvqGeAU",
        "outputId": "6f3a94ac-7a55-4885-a639-eca6146f9dac"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://ufldl.stanford.edu/housenumbers/train_32x32.mat to ./data/train_32x32.mat\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 182040794/182040794 [00:31<00:00, 5712626.39it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mn = DataLoader(datasets.MNIST(root='./data', train=True, download=True, transform=transform_mnist), batch_size=128, shuffle=True)\n",
        "sy = DataLoader(SyntheticDigits(root='./data', train=True, download=True, transform=transform_syn), batch_size=128, shuffle=True)\n",
        "\n",
        "for i in mn:\n",
        "  p, q = i\n",
        "  print(p.shape)\n",
        "  break\n",
        "for j in sy:\n",
        "  p, q = i\n",
        "  print(p.shape)\n",
        "  break"
      ],
      "metadata": {
        "id": "wW1cokmnqV49"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import tarfile\n",
        "\n",
        "# with tarfile.open('mnist_m.tar', \"r:gz\") as tar:\n",
        "#     # Extract all the contents into the current directory\n",
        "#     tar.extractall()\n",
        "\n",
        "!tar -xvf  'mnist_m.tar'"
      ],
      "metadata": {
        "id": "H00b8YkuAjwT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for data in dataloader_svhn_source:\n",
        "    imgs, labels = data\n",
        "    print(imgs.shape)\n",
        "    print(labels.shape)\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cdvKDPdXBCeb",
        "outputId": "003340d7-3d74-47f3-b193-2ce560caf7ad"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([128, 3, 32, 32])\n",
            "torch.Size([128])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "from torch.autograd import Function\n",
        "\n",
        "class ReverseLayerF(Function):\n",
        "    @staticmethod\n",
        "    def forward(ctx, x, alpha):\n",
        "        ctx.alpha = alpha\n",
        "        return x.view_as(x)\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_output):\n",
        "        output = grad_output.neg() * ctx.alpha\n",
        "        return output, None\n",
        "\n",
        "class CNNModel(nn.Module):\n",
        "    def __init__(self, input_channels=3, num_classes=10, domain_classes=2):\n",
        "        super(CNNModel, self).__init__()\n",
        "\n",
        "        # Feature extractor\n",
        "        self.feature = nn.Sequential(\n",
        "            nn.Conv2d(input_channels, 64, kernel_size=5),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.MaxPool2d(2),\n",
        "            nn.ReLU(True),\n",
        "            nn.Conv2d(64, 50, kernel_size=5),\n",
        "            nn.BatchNorm2d(50),\n",
        "            nn.Dropout2d(),\n",
        "            nn.MaxPool2d(2),\n",
        "            nn.ReLU(True)\n",
        "        )\n",
        "\n",
        "        # Class classifier\n",
        "        self.class_classifier = nn.Sequential(\n",
        "            nn.Linear(50 * 5 * 5, 100),\n",
        "            nn.BatchNorm1d(100),\n",
        "            nn.ReLU(True),\n",
        "            nn.Dropout2d(),\n",
        "            nn.Linear(100, 100),\n",
        "            nn.BatchNorm1d(100),\n",
        "            nn.ReLU(True),\n",
        "            nn.Linear(100, num_classes),\n",
        "            nn.LogSoftmax(dim=1)\n",
        "        )\n",
        "\n",
        "\n",
        "    def forward(self, input_data, alpha):\n",
        "      feature = self.feature(input_data)\n",
        "\n",
        "    # Calculate the size of the flattened features\n",
        "      size = feature.size()[1:]  # all dimensions except the batch dimension\n",
        "      num_features = 1\n",
        "      for s in size:\n",
        "          num_features *= s\n",
        "\n",
        "      feature = feature.view(-1, num_features)  # Automatically infer batch size\n",
        "      class_output = self.class_classifier(feature)\n",
        "\n",
        "      return class_output"
      ],
      "metadata": {
        "id": "8K1h5kKs-iUY"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform_syn = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Resize(32),\n",
        "    transforms.Normalize((0.4377, 0.4438, 0.4728), (0.1980, 0.2010, 0.1970))\n",
        "])\n",
        "\n",
        "# Transform for SVHN\n",
        "transform_svhn = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    # transforms.Resize(28),\n",
        "    transforms.Normalize((0.4377, 0.4438, 0.4728), (0.1980, 0.2010, 0.1970))\n",
        "])\n",
        "\n",
        "# Transform for MNIST\n",
        "transform_mnist = transforms.Compose([\n",
        "    # transforms.Resize((32, 32)),  # Resize MNIST images to 32x32 to match SVHN format\n",
        "    transforms.Grayscale(3),  # Convert MNIST images to 3 channels\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.1307,), (0.3081,))\n",
        "])\n",
        "\n",
        "# Transform for MNIST-M\n",
        "transform_mnistm = transforms.Compose([\n",
        "    transforms.Resize((32, 32)),  # Resize MNIST images to 32x32 to match SVHN format\n",
        "    transforms.Grayscale(3),  # Convert MNIST images to 3 channels\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.1307,), (0.3081,))\n",
        "])\n",
        "batch_size = 128"
      ],
      "metadata": {
        "id": "bck3gYrAJ0Bp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.backends.cudnn as cudnn\n",
        "import torch.utils.data\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# ... (other necessary imports)\n",
        "\n",
        "def test(dataset_name, epoch):\n",
        "    assert dataset_name in ['MNIST', 'mnist_m', 'svhn', 'syn']\n",
        "\n",
        "    model_root = 'mnist_model_epoch.pth'\n",
        "    image_root = 'mnist_m'\n",
        "\n",
        "    cuda = True\n",
        "    cudnn.benchmark = True\n",
        "    batch_size = 128\n",
        "    image_size = 32\n",
        "    alpha = 0\n",
        "\n",
        "    \"\"\" Load Data \"\"\"\n",
        "    transform_mnistm = transforms.Compose([\n",
        "        transforms.Resize(image_size),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
        "    ])\n",
        "    transform_mnist = transforms.Compose([\n",
        "        transforms.Resize(image_size),  # Resize MNIST images to 32x32 to match SVHN format\n",
        "        transforms.Grayscale(3),  # Convert MNIST images to 3 channels\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.1307,), (0.3081,))\n",
        "    ])\n",
        "\n",
        "\n",
        "    if dataset_name == 'mnist_m':\n",
        "        test_list = os.path.join(image_root, 'mnist_m_test_labels.txt')\n",
        "        dataset = GetLoader(\n",
        "            data_root=os.path.join(image_root, 'mnist_m_test'),\n",
        "            data_list=test_list,\n",
        "            transform=transform_mnistm\n",
        "        )\n",
        "    elif dataset_name == 'svhn':\n",
        "        transform_svhn = transforms.Compose([\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize((0.4377, 0.4438, 0.4728), (0.1980, 0.2010, 0.1970))\n",
        "        ])\n",
        "        dataset = datasets.SVHN(root='./data', split='test', download=True, transform=transform_svhn)\n",
        "    elif dataset_name == 'syn':\n",
        "        transform_syn = transforms.Compose([\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Resize(32),\n",
        "            transforms.Normalize((0.4377, 0.4438, 0.4728), (0.1980, 0.2010, 0.1970))\n",
        "        ])\n",
        "        dataset = SyntheticDigits(root='./syn_dataset', train=False, download=True, transform=transform_syn)\n",
        "\n",
        "    else:  # MNIST\n",
        "        dataset = datasets.MNIST(root='./data', train=False, transform=transform_mnist, download = True)\n",
        "\n",
        "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    \"\"\" Evaluate Model \"\"\"\n",
        "    my_net = torch.load(model_root)\n",
        "    my_net = my_net.eval()\n",
        "\n",
        "    if cuda:\n",
        "        my_net = my_net.cuda()\n",
        "\n",
        "    n_total = 0\n",
        "    n_correct = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data in dataloader:\n",
        "            t_img, t_label = data\n",
        "            if cuda:\n",
        "                t_img = t_img.cuda()\n",
        "                t_label = t_label.cuda()\n",
        "\n",
        "            class_output = my_net(input_data=t_img, alpha=alpha)\n",
        "\n",
        "            pred = class_output.data.max(1, keepdim=True)[1]\n",
        "            n_correct += pred.eq(t_label.data.view_as(pred)).cpu().sum()\n",
        "            n_total += t_label.size(0)\n",
        "\n",
        "    accu = n_correct.item() * 1.0 / n_total\n",
        "    print(f'epoch: {epoch}, accuracy of the {dataset_name} dataset: {accu}')\n"
      ],
      "metadata": {
        "id": "SgG-xBtx-iXX"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test('syn',1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yATxAKton0-l",
        "outputId": "7d27c529-336a-476a-ae89-e9c30b5ca0b5"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "./syn_dataset/SyntheticDigits/processed/synth_test.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1345: UserWarning: dropout2d: Received a 2-D input to dropout2d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout2d exists to provide channel-wise dropout on inputs with 2 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 3D or 4D inputs).\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 1, accuracy of the syn dataset: 0.3073380090024076\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cuda = True\n",
        "cudnn.benchmark = True\n",
        "lr = 1e-3\n",
        "batch_size = 128\n",
        "image_size = 32\n",
        "n_epoch = 50\n",
        "\n",
        "manual_seed = 2023\n",
        "random.seed(manual_seed)\n",
        "torch.manual_seed(manual_seed)\n",
        "\n",
        "\n",
        "my_net = CNNModel()\n",
        "optimizer = optim.Adam(my_net.parameters(), lr=lr)\n",
        "\n",
        "loss_class = torch.nn.NLLLoss()\n",
        "\n",
        "if cuda:\n",
        "    my_net = my_net.cuda()\n",
        "    loss_class = loss_class.cuda()\n",
        "\n",
        "for p in my_net.parameters():\n",
        "    p.requires_grad = True\n",
        "\n"
      ],
      "metadata": {
        "id": "-itbZ68H-iaW"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "syn_source_acc=[]\n",
        "mnist_target_acc=[]\n",
        "mnistm_target_acc = []\n",
        "svhn_target_acc = []\n",
        "\n",
        "for epoch in range(n_epoch):\n",
        "\n",
        "    len_dataloader = len(dataloader_svhn_source)\n",
        "    data_source_iter = iter(dataloader_svhn_source)\n",
        "    # data_target_iter = iter(dataloader_target)\n",
        "\n",
        "    i = 0\n",
        "    while i < len_dataloader:\n",
        "\n",
        "        p = float(i + epoch * len_dataloader) / n_epoch / len_dataloader\n",
        "        alpha = 2. / (1. + np.exp(-10 * p)) - 1\n",
        "\n",
        "        # training model using source data\n",
        "        data_source = next(data_source_iter)\n",
        "        s_img, s_label = data_source\n",
        "\n",
        "        my_net.zero_grad()\n",
        "        batch_size = len(s_label)\n",
        "        #print(batch_size)\n",
        "\n",
        "        input_img = torch.FloatTensor(batch_size, 3, image_size, image_size)\n",
        "        class_label = torch.LongTensor(batch_size)\n",
        "        domain_label = torch.zeros(batch_size)\n",
        "        domain_label = domain_label.long()\n",
        "\n",
        "        if cuda:\n",
        "            s_img = s_img.cuda()\n",
        "            s_label = s_label.cuda()\n",
        "            input_img = input_img.cuda()\n",
        "            class_label = class_label.cuda()\n",
        "\n",
        "        input_img.resize_as_(s_img).copy_(s_img)\n",
        "        class_label.resize_as_(s_label).copy_(s_label)\n",
        "        #print(input_img.shape)\n",
        "        #print(class_label.shape)\n",
        "\n",
        "        class_output = my_net(input_data=input_img, alpha=alpha)\n",
        "        #print(class_output.shape)\n",
        "        #print(domain_output.shape)\n",
        "        err_s_label = loss_class(class_output, class_label)\n",
        "\n",
        "        # training model using target data\n",
        "\n",
        "        err = err_s_label\n",
        "        err.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        i += 1\n",
        "\n",
        "    print('epoch: %d, [iter: %d / all %d], err_s_label: %f' % (epoch, i, len_dataloader, err_s_label.cpu().data.numpy()))\n",
        "\n",
        "    torch.save(my_net, '../mnist_model_epoch.pth')\n",
        "    # mnist=test('MNIST', epoch)\n",
        "    # mnist_target_acc.append(mnist)\n",
        "\n",
        "    # mnistm=test('mnist_m', epoch)\n",
        "    # mnistm_target_acc.append(mnistm)\n",
        "\n",
        "    # svhn = test('svhn',epoch)\n",
        "    # svhn_target_acc.append(svhn)\n",
        "\n",
        "    syn = test('syn', epoch)\n",
        "    syn_source_acc.append(syn)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GOu16HMX-idF",
        "outputId": "7ce8e270-06b2-4d53-b467-6c36f399beb1"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 0, [iter: 573 / all 573], err_s_label: 0.936699\n",
            "./syn_dataset/SyntheticDigits/processed/synth_test.pt\n",
            "epoch: 0, accuracy of the syn dataset: 0.3073380090024076\n",
            "epoch: 1, [iter: 573 / all 573], err_s_label: 0.678260\n",
            "./syn_dataset/SyntheticDigits/processed/synth_test.pt\n",
            "epoch: 1, accuracy of the syn dataset: 0.3073380090024076\n",
            "epoch: 2, [iter: 573 / all 573], err_s_label: 0.878667\n",
            "./syn_dataset/SyntheticDigits/processed/synth_test.pt\n",
            "epoch: 2, accuracy of the syn dataset: 0.3073380090024076\n",
            "epoch: 3, [iter: 573 / all 573], err_s_label: 0.665408\n",
            "./syn_dataset/SyntheticDigits/processed/synth_test.pt\n",
            "epoch: 3, accuracy of the syn dataset: 0.3073380090024076\n",
            "epoch: 4, [iter: 573 / all 573], err_s_label: 0.624948\n",
            "./syn_dataset/SyntheticDigits/processed/synth_test.pt\n",
            "epoch: 4, accuracy of the syn dataset: 0.3073380090024076\n",
            "epoch: 5, [iter: 573 / all 573], err_s_label: 0.404019\n",
            "./syn_dataset/SyntheticDigits/processed/synth_test.pt\n",
            "epoch: 5, accuracy of the syn dataset: 0.3073380090024076\n",
            "epoch: 6, [iter: 573 / all 573], err_s_label: 0.718561\n",
            "./syn_dataset/SyntheticDigits/processed/synth_test.pt\n",
            "epoch: 6, accuracy of the syn dataset: 0.3073380090024076\n",
            "epoch: 7, [iter: 573 / all 573], err_s_label: 0.193009\n",
            "./syn_dataset/SyntheticDigits/processed/synth_test.pt\n",
            "epoch: 7, accuracy of the syn dataset: 0.3073380090024076\n",
            "epoch: 8, [iter: 573 / all 573], err_s_label: 0.281823\n",
            "./syn_dataset/SyntheticDigits/processed/synth_test.pt\n",
            "epoch: 8, accuracy of the syn dataset: 0.3073380090024076\n",
            "epoch: 9, [iter: 573 / all 573], err_s_label: 0.416846\n",
            "./syn_dataset/SyntheticDigits/processed/synth_test.pt\n",
            "epoch: 9, accuracy of the syn dataset: 0.3073380090024076\n",
            "epoch: 10, [iter: 573 / all 573], err_s_label: 1.016126\n",
            "./syn_dataset/SyntheticDigits/processed/synth_test.pt\n",
            "epoch: 10, accuracy of the syn dataset: 0.3073380090024076\n",
            "epoch: 11, [iter: 573 / all 573], err_s_label: 0.347636\n",
            "./syn_dataset/SyntheticDigits/processed/synth_test.pt\n",
            "epoch: 11, accuracy of the syn dataset: 0.3073380090024076\n",
            "epoch: 12, [iter: 573 / all 573], err_s_label: 0.240344\n",
            "./syn_dataset/SyntheticDigits/processed/synth_test.pt\n",
            "epoch: 12, accuracy of the syn dataset: 0.3073380090024076\n",
            "epoch: 13, [iter: 573 / all 573], err_s_label: 0.404110\n",
            "./syn_dataset/SyntheticDigits/processed/synth_test.pt\n",
            "epoch: 13, accuracy of the syn dataset: 0.3073380090024076\n",
            "epoch: 14, [iter: 573 / all 573], err_s_label: 0.380180\n",
            "./syn_dataset/SyntheticDigits/processed/synth_test.pt\n",
            "epoch: 14, accuracy of the syn dataset: 0.3073380090024076\n",
            "epoch: 15, [iter: 573 / all 573], err_s_label: 0.466051\n",
            "./syn_dataset/SyntheticDigits/processed/synth_test.pt\n",
            "epoch: 15, accuracy of the syn dataset: 0.3073380090024076\n",
            "epoch: 16, [iter: 573 / all 573], err_s_label: 0.414344\n",
            "./syn_dataset/SyntheticDigits/processed/synth_test.pt\n",
            "epoch: 16, accuracy of the syn dataset: 0.3073380090024076\n",
            "epoch: 17, [iter: 573 / all 573], err_s_label: 0.690447\n",
            "./syn_dataset/SyntheticDigits/processed/synth_test.pt\n",
            "epoch: 17, accuracy of the syn dataset: 0.3073380090024076\n",
            "epoch: 18, [iter: 573 / all 573], err_s_label: 0.366266\n",
            "./syn_dataset/SyntheticDigits/processed/synth_test.pt\n",
            "epoch: 18, accuracy of the syn dataset: 0.3073380090024076\n",
            "epoch: 19, [iter: 573 / all 573], err_s_label: 0.623077\n",
            "./syn_dataset/SyntheticDigits/processed/synth_test.pt\n",
            "epoch: 19, accuracy of the syn dataset: 0.3073380090024076\n",
            "epoch: 20, [iter: 573 / all 573], err_s_label: 1.052838\n",
            "./syn_dataset/SyntheticDigits/processed/synth_test.pt\n",
            "epoch: 20, accuracy of the syn dataset: 0.3073380090024076\n",
            "epoch: 21, [iter: 573 / all 573], err_s_label: 0.539749\n",
            "./syn_dataset/SyntheticDigits/processed/synth_test.pt\n",
            "epoch: 21, accuracy of the syn dataset: 0.3073380090024076\n",
            "epoch: 22, [iter: 573 / all 573], err_s_label: 0.353494\n",
            "./syn_dataset/SyntheticDigits/processed/synth_test.pt\n",
            "epoch: 22, accuracy of the syn dataset: 0.3073380090024076\n",
            "epoch: 23, [iter: 573 / all 573], err_s_label: 0.552295\n",
            "./syn_dataset/SyntheticDigits/processed/synth_test.pt\n",
            "epoch: 23, accuracy of the syn dataset: 0.3073380090024076\n",
            "epoch: 24, [iter: 573 / all 573], err_s_label: 0.350716\n",
            "./syn_dataset/SyntheticDigits/processed/synth_test.pt\n",
            "epoch: 24, accuracy of the syn dataset: 0.3073380090024076\n",
            "epoch: 25, [iter: 573 / all 573], err_s_label: 0.191982\n",
            "./syn_dataset/SyntheticDigits/processed/synth_test.pt\n",
            "epoch: 25, accuracy of the syn dataset: 0.3073380090024076\n",
            "epoch: 26, [iter: 573 / all 573], err_s_label: 0.320107\n",
            "./syn_dataset/SyntheticDigits/processed/synth_test.pt\n",
            "epoch: 26, accuracy of the syn dataset: 0.3073380090024076\n",
            "epoch: 27, [iter: 573 / all 573], err_s_label: 0.510203\n",
            "./syn_dataset/SyntheticDigits/processed/synth_test.pt\n",
            "epoch: 27, accuracy of the syn dataset: 0.3073380090024076\n",
            "epoch: 28, [iter: 573 / all 573], err_s_label: 0.307578\n",
            "./syn_dataset/SyntheticDigits/processed/synth_test.pt\n",
            "epoch: 28, accuracy of the syn dataset: 0.3073380090024076\n",
            "epoch: 29, [iter: 573 / all 573], err_s_label: 0.240448\n",
            "./syn_dataset/SyntheticDigits/processed/synth_test.pt\n",
            "epoch: 29, accuracy of the syn dataset: 0.3073380090024076\n",
            "epoch: 30, [iter: 573 / all 573], err_s_label: 0.846222\n",
            "./syn_dataset/SyntheticDigits/processed/synth_test.pt\n",
            "epoch: 30, accuracy of the syn dataset: 0.3073380090024076\n",
            "epoch: 31, [iter: 573 / all 573], err_s_label: 0.353768\n",
            "./syn_dataset/SyntheticDigits/processed/synth_test.pt\n",
            "epoch: 31, accuracy of the syn dataset: 0.3073380090024076\n",
            "epoch: 32, [iter: 573 / all 573], err_s_label: 0.393676\n",
            "./syn_dataset/SyntheticDigits/processed/synth_test.pt\n",
            "epoch: 32, accuracy of the syn dataset: 0.3073380090024076\n",
            "epoch: 33, [iter: 573 / all 573], err_s_label: 0.771698\n",
            "./syn_dataset/SyntheticDigits/processed/synth_test.pt\n",
            "epoch: 33, accuracy of the syn dataset: 0.3073380090024076\n",
            "epoch: 34, [iter: 573 / all 573], err_s_label: 0.244846\n",
            "./syn_dataset/SyntheticDigits/processed/synth_test.pt\n",
            "epoch: 34, accuracy of the syn dataset: 0.3073380090024076\n",
            "epoch: 35, [iter: 573 / all 573], err_s_label: 0.302007\n",
            "./syn_dataset/SyntheticDigits/processed/synth_test.pt\n",
            "epoch: 35, accuracy of the syn dataset: 0.3073380090024076\n",
            "epoch: 36, [iter: 573 / all 573], err_s_label: 0.385602\n",
            "./syn_dataset/SyntheticDigits/processed/synth_test.pt\n",
            "epoch: 36, accuracy of the syn dataset: 0.3073380090024076\n",
            "epoch: 37, [iter: 573 / all 573], err_s_label: 0.490584\n",
            "./syn_dataset/SyntheticDigits/processed/synth_test.pt\n",
            "epoch: 37, accuracy of the syn dataset: 0.3073380090024076\n",
            "epoch: 38, [iter: 573 / all 573], err_s_label: 0.275097\n",
            "./syn_dataset/SyntheticDigits/processed/synth_test.pt\n",
            "epoch: 38, accuracy of the syn dataset: 0.3073380090024076\n",
            "epoch: 39, [iter: 573 / all 573], err_s_label: 0.421399\n",
            "./syn_dataset/SyntheticDigits/processed/synth_test.pt\n",
            "epoch: 39, accuracy of the syn dataset: 0.3073380090024076\n",
            "epoch: 40, [iter: 573 / all 573], err_s_label: 0.521916\n",
            "./syn_dataset/SyntheticDigits/processed/synth_test.pt\n",
            "epoch: 40, accuracy of the syn dataset: 0.3073380090024076\n",
            "epoch: 41, [iter: 573 / all 573], err_s_label: 0.437849\n",
            "./syn_dataset/SyntheticDigits/processed/synth_test.pt\n",
            "epoch: 41, accuracy of the syn dataset: 0.3073380090024076\n",
            "epoch: 42, [iter: 573 / all 573], err_s_label: 0.180806\n",
            "./syn_dataset/SyntheticDigits/processed/synth_test.pt\n",
            "epoch: 42, accuracy of the syn dataset: 0.3073380090024076\n",
            "epoch: 43, [iter: 573 / all 573], err_s_label: 0.198019\n",
            "./syn_dataset/SyntheticDigits/processed/synth_test.pt\n",
            "epoch: 43, accuracy of the syn dataset: 0.3073380090024076\n",
            "epoch: 44, [iter: 573 / all 573], err_s_label: 0.276729\n",
            "./syn_dataset/SyntheticDigits/processed/synth_test.pt\n",
            "epoch: 44, accuracy of the syn dataset: 0.3073380090024076\n",
            "epoch: 45, [iter: 573 / all 573], err_s_label: 0.336464\n",
            "./syn_dataset/SyntheticDigits/processed/synth_test.pt\n",
            "epoch: 45, accuracy of the syn dataset: 0.3073380090024076\n",
            "epoch: 46, [iter: 573 / all 573], err_s_label: 0.455752\n",
            "./syn_dataset/SyntheticDigits/processed/synth_test.pt\n",
            "epoch: 46, accuracy of the syn dataset: 0.3073380090024076\n",
            "epoch: 47, [iter: 573 / all 573], err_s_label: 0.397248\n",
            "./syn_dataset/SyntheticDigits/processed/synth_test.pt\n",
            "epoch: 47, accuracy of the syn dataset: 0.3073380090024076\n",
            "epoch: 48, [iter: 573 / all 573], err_s_label: 0.501680\n",
            "./syn_dataset/SyntheticDigits/processed/synth_test.pt\n",
            "epoch: 48, accuracy of the syn dataset: 0.3073380090024076\n",
            "epoch: 49, [iter: 573 / all 573], err_s_label: 0.520639\n",
            "./syn_dataset/SyntheticDigits/processed/synth_test.pt\n",
            "epoch: 49, accuracy of the syn dataset: 0.3073380090024076\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SVHN trained prediction on mnist,mnist-m"
      ],
      "metadata": {
        "id": "3g1WrIu9IzB2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test('MNIST',1)\n",
        "test('mnist_m',2)\n",
        "test('svhn',3)"
      ],
      "metadata": {
        "id": "YPQrVyotI4p2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MNIST trained prediction on mnist-m,svhn"
      ],
      "metadata": {
        "id": "s4qgtozPGUfW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test('MNIST',1)\n",
        "test('mnist_m',2)\n",
        "test('svhn',3)"
      ],
      "metadata": {
        "id": "DKjOcF7Q-ifs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Z2jMXHoL-iis"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Y9ehMAsa-ili"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}